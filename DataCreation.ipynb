{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35320,"status":"ok","timestamp":1685296841860,"user":{"displayName":"Ahmad Mujtaba Muhammad Bashir","userId":"03357400955580990013"},"user_tz":-300},"id":"kIcnJR3Ngpli","outputId":"af4653a9-0998-4d6f-88aa-5498932d9d76"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/mydrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/mydrive')\n"],"id":"kIcnJR3Ngpli"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143884,"status":"ok","timestamp":1685296985737,"user":{"displayName":"Ahmad Mujtaba Muhammad Bashir","userId":"03357400955580990013"},"user_tz":-300},"id":"SFB6WmXJ1Kai","outputId":"bb73f3b4-1f0b-48ed-f031-abca4e9d7aae"},"outputs":[{"output_type":"stream","name":"stdout","text":["          V_in  Measured_RPM  Vibration_1  Vibration_2  Vibration_3  Target\n","0      1.54509      1.453696    -0.292070     2.254716     0.692729       0\n","1      1.54509      1.453696     0.224638    -2.102691    -1.919793       0\n","2      1.54509      1.453696    -0.585772    -1.946220    -1.288580       0\n","3      1.54509      1.453696     0.525003     1.828253     0.132137       0\n","4      1.54509      1.453696    -4.995004    -0.195169     3.100203       0\n","...        ...           ...          ...          ...          ...     ...\n","49995 -1.28523     -1.322414     0.067192    -0.000344    -0.104108       4\n","49996 -1.28523     -1.322414    -0.017031     0.012491    -0.071417       4\n","49997 -1.28523     -1.322414    -0.001922     0.033028    -0.118476       4\n","49998 -1.28523     -1.322414    -0.025709    -0.038015    -0.035186       4\n","49999 -1.28523     -1.322414     0.007841    -0.022971    -0.080995       4\n","\n","[250000 rows x 6 columns]\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# List of file paths\n","file_paths = [\"/content/mydrive/MyDrive/Kaggle/Dataset/0D.csv\", \"/content/mydrive/MyDrive/Kaggle/Dataset/1D.csv\", \"/content/mydrive/MyDrive/Kaggle/Dataset/2D.csv\", \"/content/mydrive/MyDrive/Kaggle/Dataset/3D.csv\", \"/content/mydrive/MyDrive/Kaggle/Dataset/4D.csv\"]\n","\n","# List of target values for each file\n","target_values = [0, 1, 2, 3, 4]\n","\n","# Number of samples to extract from the middle of each CSV\n","num_samples = 50000\n","\n","# List to store the updated DataFrames\n","updated_dfs = []\n","\n","# Preprocessing steps\n","scaler = StandardScaler()\n","\n","# Loop through each file\n","for file_path, target_value in zip(file_paths, target_values):\n","    # Read the CSV file\n","    df = pd.read_csv(file_path)\n","    \n","    # Extract the desired number of samples from the middle of the DataFrame\n","    start_index = max(0, df.shape[0] // 2 - num_samples // 2)\n","    end_index = start_index + num_samples\n","    df = df.iloc[start_index:end_index]\n","    \n","    # Data preprocessing steps\n","    # Handle missing values\n","    df = df.interpolate()\n","\n","    # Data normalization\n","    features = df\n","    normalized_features = scaler.fit_transform(features)\n","    df_normalized = pd.DataFrame(normalized_features, columns=features.columns)\n","    \n","    # Add a target column to the DataFrame\n","    df_normalized['Target'] = target_value\n","    \n","    # Append the updated DataFrame to the list\n","    updated_dfs.append(df_normalized)\n","\n","# Concatenate all DataFrames into a single DataFrame\n","combined_df = pd.concat(updated_dfs)\n","\n","# Save the combined DataFrame to a CSV file\n","combined_df.to_csv(\"/content/mydrive/MyDrive/Kaggle/FT_combined_data.csv\", index=False)\n","\n","# Print the combined DataFrame\n","print(combined_df)\n"],"id":"SFB6WmXJ1Kai"},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# List of file paths\n","file_paths = [\"/content/mydrive/MyDrive/Kaggle/Dataset/0E.csv\", \"/content/mydrive/MyDrive/Kaggle/Dataset/1E.csv\", \"/content/mydrive/MyDrive/Kaggle/Dataset/2E.csv\", \"/content/mydrive/MyDrive/Kaggle/Dataset/3E.csv\", \"/content/mydrive/MyDrive/Kaggle/Dataset/4E.csv\"]\n","\n","# List of target values for each file\n","target_values = [0, 1, 2, 3, 4]\n","\n","# Number of samples to extract from the middle of each CSV\n","num_samples = 5000\n","\n","# List to store the updated DataFrames\n","updated_dfs = []\n","\n","# Preprocessing steps\n","scaler = StandardScaler()\n","\n","# Loop through each file\n","for file_path, target_value in zip(file_paths, target_values):\n","    # Read the CSV file\n","    df = pd.read_csv(file_path)\n","    \n","    # Extract the desired number of samples from the middle of the DataFrame\n","    start_index = max(0, df.shape[0] // 2 - num_samples // 2)\n","    end_index = start_index + num_samples\n","    df = df.iloc[start_index:end_index]\n","    \n","    # Data preprocessing steps\n","    # Handle missing values\n","    df = df.interpolate()\n","\n","    # Data normalization\n","    features = df\n","    normalized_features = scaler.fit_transform(features)\n","    df_normalized = pd.DataFrame(normalized_features, columns=features.columns)\n","    \n","    # Add a target column to the DataFrame\n","    df_normalized['Target'] = target_value\n","    \n","    # Append the updated DataFrame to the list\n","    updated_dfs.append(df_normalized)\n","\n","# Concatenate all DataFrames into a single DataFrame\n","combined_df = pd.concat(updated_dfs)\n","\n","# Save the combined DataFrame to a CSV file\n","combined_df.to_csv(\"/content/mydrive/MyDrive/Kaggle/E_FT_combined_data.csv\", index=False)\n","\n","# Print the combined DataFrame\n","print(combined_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sn6USZWw3LUP","executionInfo":{"status":"ok","timestamp":1685302695519,"user_tz":-300,"elapsed":50717,"user":{"displayName":"Ahmad Mujtaba Muhammad Bashir","userId":"03357400955580990013"}},"outputId":"68abfd27-34ff-4e1a-ed40-07b3b8246bbc"},"id":"Sn6USZWw3LUP","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["      V_in  Measured_RPM  Vibration_1  Vibration_2  Vibration_3  Target\n","0      0.0     -3.167609    -2.235252     1.974175     2.729873       0\n","1      0.0     -3.167609    -1.185190    -0.872208     0.887431       0\n","2      0.0     -3.167609    -0.270910    -0.558714     0.888415       0\n","3      0.0     -3.167609     0.581266    -0.151156    -1.655768       0\n","4      0.0     -3.167609     1.668626     1.478789    -5.452359       0\n","...    ...           ...          ...          ...          ...     ...\n","4995   0.0     -1.000000    -0.262406     0.532538     0.265492       4\n","4996   0.0     -1.000000     0.740770     1.486638    -0.948785       4\n","4997   0.0     -1.000000     0.849010    -1.761848    -0.906289       4\n","4998   0.0     -1.000000     0.368707    -0.942933    -0.124540       4\n","4999   0.0     -1.000000    -1.556322     1.918962     1.245834       4\n","\n","[25000 rows x 6 columns]\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"papermill":{"default_parameters":{},"duration":null,"end_time":null,"environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-05-27T18:34:04.612264","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}